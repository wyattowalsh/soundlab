{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wyattowalsh/soundlab/blob/main/soundlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# üéµ SoundLab v1.0\n",
    "\n",
    "**Production-ready audio processing toolkit for stem separation, vocal isolation, drum transcription, and MIDI conversion.**\n",
    "\n",
    "## Features\n",
    "- üéöÔ∏è **Stem Separation** ‚Äî Split any song into vocals, drums, bass, and more\n",
    "- üé§ **Vocal Isolation** ‚Äî Extract vocals or create instrumentals with one command\n",
    "- ü•Å **Drum-to-MIDI** ‚Äî Transcribe drum patterns with kick/snare/hihat detection\n",
    "- üéπ **Audio-to-MIDI** ‚Äî Convert melodies to MIDI using neural transcription\n",
    "- üé® **Effects Processing** ‚Äî Apply compression, EQ, reverb, and more\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üöÄ Setup\n",
    "\n",
    "Install SoundLab and verify GPU availability for faster processing."
   ],
   "metadata": {
    "id": "setup-header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Install SoundLab from GitHub with all features\n!pip install -q \"soundlab[separation,transcription] @ git+https://github.com/wyattowalsh/soundlab.git\"\n\n# Check GPU availability\nimport torch\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"‚úÖ SoundLab installed | Device: {device.upper()}\")\n\nif device == \"cpu\":\n    print(\"‚ö†Ô∏è  GPU recommended for faster processing. Go to Runtime > Change runtime type > GPU\")",
   "metadata": {
    "id": "install"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Core imports\nfrom pathlib import Path\nfrom IPython.display import Audio, display, HTML\n\nfrom soundlab.io import load_audio, save_audio\nfrom soundlab.separation import StemSeparator, SeparationConfig, DemucsModel\nfrom soundlab.transcription import DrumTranscriber, MIDITranscriber, TranscriptionConfig, get_transcriber\nfrom soundlab.io.midi_io import load_midi, save_midi\n\nprint(\"‚úÖ All modules imported successfully!\")",
   "metadata": {
    "id": "imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üìÅ Upload Your Audio\n",
    "\n",
    "Upload an audio file (MP3, WAV, FLAC) or use the sample."
   ],
   "metadata": {
    "id": "upload-header"
   }
  },
  {
   "cell_type": "code",
   "source": "# @title Upload Audio File\n# @markdown Upload your own audio or use a sample file.\n\nUSE_SAMPLE = True  # @param {type: \"boolean\"}\n\nif USE_SAMPLE:\n    # Download a sample audio file\n    !wget -q -O sample.mp3 \"https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3\"\n    AUDIO_PATH = \"sample.mp3\"\n    print(\"üì• Downloaded sample audio\")\nelse:\n    from google.colab import files\n    uploaded = files.upload()\n    AUDIO_PATH = list(uploaded.keys())[0]\n    print(f\"üì§ Uploaded: {AUDIO_PATH}\")\n\n# Load and preview\naudio = load_audio(AUDIO_PATH)\nprint(f\"\\nüìä Audio Info:\")\nprint(f\"   Duration: {audio.duration_seconds:.1f}s\")\nprint(f\"   Sample Rate: {audio.sample_rate} Hz\")\nprint(f\"   Channels: {audio.channels}\")\n\nprint(\"\\nüéß Preview:\")\ndisplay(Audio(audio.samples.T, rate=audio.sample_rate))",
   "metadata": {
    "id": "upload"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## üéöÔ∏è Stem Separation\n",
    "\n",
    "Split your audio into individual stems using Demucs neural network models.\n",
    "\n",
    "| Model | Stems | Quality | Speed |\n",
    "|-------|-------|---------|-------|\n",
    "| `htdemucs_ft` | 4 (vocals, drums, bass, other) | Best | Fast |\n",
    "| `htdemucs_6s` | 6 (+piano, guitar) | Best | Slower |\n",
    "| `mdx_extra` | 4 | Good | Fastest |"
   ],
   "metadata": {
    "id": "separation-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Configure Stem Separation\n",
    "# @markdown Choose your model and settings.\n",
    "\n",
    "MODEL = \"htdemucs_ft\"  # @param [\"htdemucs\", \"htdemucs_ft\", \"htdemucs_6s\", \"mdx_extra\"]\n",
    "DEVICE = \"auto\"  # @param [\"auto\", \"cuda\", \"cpu\"]\n",
    "\n",
    "# Create separator\n",
    "config = SeparationConfig(\n",
    "    model=DemucsModel(MODEL),\n",
    "    device=DEVICE,\n",
    ")\n",
    "separator = StemSeparator(config)\n",
    "\n",
    "print(f\"üéõÔ∏è Model: {MODEL}\")\n",
    "print(f\"   Device: {DEVICE}\")\n",
    "print(f\"   Stems: {config.model.stems}\")"
   ],
   "metadata": {
    "id": "separation-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title Run Separation\n# @markdown This may take 1-5 minutes depending on audio length and GPU.\n\nOUTPUT_DIR = Path(\"stems\")\nOUTPUT_DIR.mkdir(exist_ok=True)\n\nprint(\"üé∂ Separating stems...\")\nresult = separator.separate(AUDIO_PATH, OUTPUT_DIR)\n\nprint(f\"\\n‚úÖ Separation complete in {result.processing_time_seconds:.1f}s\")\nprint(f\"\\nüìÇ Output stems:\")\nfor stem_name, stem_path in result.stems.items():\n    print(f\"   {stem_name}: {stem_path}\")",
   "metadata": {
    "id": "run-separation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Preview Separated Stems\n",
    "# @markdown Listen to each stem individually.\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "for stem_name, stem_path in result.stems.items():\n",
    "    audio_data, sr = sf.read(stem_path)\n",
    "    print(f\"\\nüéß {stem_name.upper()}\")\n",
    "    display(Audio(audio_data.T if audio_data.ndim > 1 else audio_data, rate=sr))"
   ],
   "metadata": {
    "id": "preview-stems"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## üé§ Vocal Isolation\n",
    "\n",
    "**New in v1.0!** Extract just vocals and instrumental with two-stem mode."
   ],
   "metadata": {
    "id": "vocal-isolation-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Isolate Vocals\n",
    "# @markdown Extract vocals and create an instrumental track.\n",
    "\n",
    "# Configure for vocal isolation\n",
    "vocal_config = SeparationConfig(\n",
    "    model=DemucsModel.HTDEMUCS_FT,\n",
    "    two_stems=\"vocals\",  # Key setting for vocal isolation\n",
    ")\n",
    "vocal_separator = StemSeparator(vocal_config)\n",
    "\n",
    "VOCAL_OUTPUT = Path(\"vocal_isolation\")\n",
    "VOCAL_OUTPUT.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üé§ Isolating vocals...\")\n",
    "vocal_result = vocal_separator.separate(AUDIO_PATH, VOCAL_OUTPUT)\n",
    "\n",
    "print(f\"\\n‚úÖ Vocal isolation complete!\")\n",
    "print(f\"\\nüìÇ Output:\")\n",
    "for stem_name, stem_path in vocal_result.stems.items():\n",
    "    print(f\"   {stem_name}: {stem_path}\")"
   ],
   "metadata": {
    "id": "vocal-isolation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Preview Vocals vs Instrumental\n",
    "\n",
    "# Load and play vocals\n",
    "vocals_path = vocal_result.stems.get(\"vocals\")\n",
    "if vocals_path and vocals_path.exists():\n",
    "    vocals_audio, sr = sf.read(vocals_path)\n",
    "    print(\"üé§ VOCALS\")\n",
    "    display(Audio(vocals_audio.T if vocals_audio.ndim > 1 else vocals_audio, rate=sr))\n",
    "\n",
    "# Load and play instrumental (no_vocals)\n",
    "instrumental_path = vocal_result.stems.get(\"no_vocals\")\n",
    "if instrumental_path and instrumental_path.exists():\n",
    "    instrumental_audio, sr = sf.read(instrumental_path)\n",
    "    print(\"\\nüé∏ INSTRUMENTAL\")\n",
    "    display(Audio(instrumental_audio.T if instrumental_audio.ndim > 1 else instrumental_audio, rate=sr))"
   ],
   "metadata": {
    "id": "preview-vocals"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## ü•Å Drum-to-MIDI Transcription\n",
    "\n",
    "**New in v1.0!** Convert drum tracks to MIDI with automatic kick/snare/hihat detection."
   ],
   "metadata": {
    "id": "drum-midi-header"
   }
  },
  {
   "cell_type": "code",
   "source": "# @title Configure Drum Transcription\n# @markdown Tune parameters for your drum audio.\n\nfrom soundlab.transcription.drum_backend import DrumConfig\n\nONSET_THRESHOLD = 0.5  # @param {type: \"slider\", min: 0.1, max: 0.9, step: 0.1}\nNOTE_DURATION = 0.1  # @param {type: \"slider\", min: 0.05, max: 0.2, step: 0.01}\n\ndrum_config = DrumConfig(\n    onset_thresh=ONSET_THRESHOLD,\n    note_duration=NOTE_DURATION,\n)\n\nprint(\"ü•Å Drum Transcription Config:\")\nprint(f\"   Onset threshold: {drum_config.onset_thresh}\")\nprint(f\"   Note duration: {drum_config.note_duration}s\")\nprint(f\"\\n   MIDI Mapping:\")\nprint(f\"   Kick: {drum_config.kick_pitch} | Snare: {drum_config.snare_pitch} | Hi-hat: {drum_config.hihat_pitch}\")",
   "metadata": {
    "id": "drum-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title Transcribe Drums to MIDI\n# @markdown Uses the separated drum stem from earlier.\n\n# Get drum stem path\ndrum_stem = result.stems.get(\"drums\")\n\nif drum_stem and Path(drum_stem).exists():\n    drum_transcriber = DrumTranscriber(config=drum_config)\n    \n    MIDI_OUTPUT = Path(\"midi_output\")\n    MIDI_OUTPUT.mkdir(exist_ok=True)\n    \n    print(\"üéπ Transcribing drums to MIDI...\")\n    midi_result = drum_transcriber.transcribe(drum_stem, MIDI_OUTPUT)\n    \n    print(f\"\\n‚úÖ Transcription complete!\")\n    print(f\"   Notes detected: {len(midi_result.notes)}\")\n    print(f\"   Output: {midi_result.path}\")\n    print(f\"   Processing time: {midi_result.processing_time:.2f}s\")\nelse:\n    print(\"‚ö†Ô∏è Run stem separation first to get a drum track\")",
   "metadata": {
    "id": "drum-transcribe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Analyze Drum Hits\n",
    "# @markdown View detected drum events by type.\n",
    "\n",
    "if 'midi_result' in dir() and midi_result.notes:\n",
    "    # Count by pitch (drum type)\n",
    "    from collections import Counter\n",
    "    \n",
    "    pitch_counts = Counter(n.pitch for n in midi_result.notes)\n",
    "    \n",
    "    DRUM_NAMES = {36: \"Kick\", 38: \"Snare\", 42: \"Hi-hat (closed)\", 46: \"Hi-hat (open)\"}\n",
    "    \n",
    "    print(\"üìä Drum Hit Analysis:\")\n",
    "    print(f\"   Total hits: {len(midi_result.notes)}\")\n",
    "    print(\"\\n   By type:\")\n",
    "    for pitch, count in sorted(pitch_counts.items()):\n",
    "        name = DRUM_NAMES.get(pitch, f\"MIDI {pitch}\")\n",
    "        print(f\"   {name}: {count} hits\")\n",
    "    \n",
    "    # Show first few events\n",
    "    print(\"\\n   First 10 events:\")\n",
    "    for i, note in enumerate(midi_result.notes[:10]):\n",
    "        name = DRUM_NAMES.get(note.pitch, f\"MIDI {note.pitch}\")\n",
    "        print(f\"   {note.start:.3f}s - {name} (vel: {note.velocity})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Run drum transcription first\")"
   ],
   "metadata": {
    "id": "analyze-drums"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## üéπ Melodic Audio-to-MIDI\n",
    "\n",
    "Transcribe melodic content (vocals, piano, bass) to MIDI using neural pitch detection."
   ],
   "metadata": {
    "id": "melodic-midi-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Transcribe Melody to MIDI\n",
    "# @markdown Works best on isolated stems (vocals, bass, piano).\n",
    "\n",
    "STEM_TO_TRANSCRIBE = \"bass\"  # @param [\"vocals\", \"bass\", \"other\"]\n",
    "\n",
    "stem_path = result.stems.get(STEM_TO_TRANSCRIBE)\n",
    "\n",
    "if stem_path and Path(stem_path).exists():\n",
    "    # Get the best available transcriber for your Python version\n",
    "    melodic_transcriber = get_transcriber(backend=\"auto\")\n",
    "    \n",
    "    print(f\"üéπ Transcribing {STEM_TO_TRANSCRIBE} to MIDI...\")\n",
    "    print(f\"   Using: {type(melodic_transcriber).__name__}\")\n",
    "    \n",
    "    melodic_result = melodic_transcriber.transcribe(stem_path, MIDI_OUTPUT)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Transcription complete!\")\n",
    "    print(f\"   Notes detected: {len(melodic_result.notes)}\")\n",
    "    print(f\"   Output: {melodic_result.path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Stem '{STEM_TO_TRANSCRIBE}' not found. Run separation first.\")"
   ],
   "metadata": {
    "id": "melodic-transcribe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## üíæ Download Results\n",
    "\n",
    "Download all separated stems and MIDI files as a ZIP archive."
   ],
   "metadata": {
    "id": "download-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Create Download Package\n",
    "# @markdown Bundle all outputs into a ZIP file.\n",
    "\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Create output bundle\n",
    "BUNDLE_DIR = Path(\"soundlab_output\")\n",
    "BUNDLE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy stems\n",
    "if OUTPUT_DIR.exists():\n",
    "    for f in OUTPUT_DIR.glob(\"*\"):\n",
    "        shutil.copy(f, BUNDLE_DIR)\n",
    "\n",
    "# Copy vocal isolation\n",
    "if VOCAL_OUTPUT.exists():\n",
    "    for f in VOCAL_OUTPUT.glob(\"*\"):\n",
    "        shutil.copy(f, BUNDLE_DIR)\n",
    "\n",
    "# Copy MIDI\n",
    "if MIDI_OUTPUT.exists():\n",
    "    for f in MIDI_OUTPUT.glob(\"*.mid\"):\n",
    "        shutil.copy(f, BUNDLE_DIR)\n",
    "\n",
    "# Create ZIP\n",
    "zip_path = shutil.make_archive(\"soundlab_output\", \"zip\", BUNDLE_DIR)\n",
    "print(f\"üì¶ Created: {zip_path}\")\n",
    "print(f\"\\nüìÇ Contents:\")\n",
    "for f in BUNDLE_DIR.glob(\"*\"):\n",
    "    print(f\"   {f.name}\")\n",
    "\n",
    "# Download\n",
    "print(\"\\n‚¨áÔ∏è Starting download...\")\n",
    "files.download(zip_path)"
   ],
   "metadata": {
    "id": "download"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## üìö What's Next?\n",
    "\n",
    "**More Examples:**\n",
    "- [Stem Separation Deep Dive](./notebooks/examples/stem_separation.ipynb)\n",
    "- [MIDI Transcription Guide](./notebooks/examples/midi_transcription.ipynb)\n",
    "- [Voice Conversion](./notebooks/examples/voice_conversion.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "- üìñ [Documentation](https://github.com/wyattowalsh/soundlab)\n",
    "- üêõ [Report Issues](https://github.com/wyattowalsh/soundlab/issues)\n",
    "- ‚≠ê [Star on GitHub](https://github.com/wyattowalsh/soundlab)\n",
    "\n",
    "---\n",
    "\n",
    "**SoundLab v1.0** ‚Äî Production-ready audio processing for stem separation, vocal isolation, and MIDI transcription."
   ],
   "metadata": {
    "id": "footer"
   }
  }
 ]
}