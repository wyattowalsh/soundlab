{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI Transcription with SoundLab\n",
    "\n",
    "This notebook demonstrates how to use SoundLab's audio-to-MIDI transcription powered by Basic Pitch.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Transcribe audio to MIDI notes\n",
    "- Configure transcription parameters\n",
    "- Visualize piano rolls\n",
    "- Work with note events\n",
    "- Export MIDI files\n",
    "- Best practices for transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundlab\n",
    "from soundlab.transcription import MIDITranscriber, TranscriptionConfig\n",
    "from soundlab.io import load_audio, save_midi, load_midi\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization and audio playback\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"SoundLab version: {soundlab.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic MIDI Transcription\n",
    "\n",
    "Let's start by transcribing a simple melody to MIDI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transcriber with default settings\n",
    "transcriber = MIDITranscriber()\n",
    "\n",
    "# Path to your audio file (monophonic melody works best)\n",
    "# Replace with your own audio file or use test fixtures\n",
    "input_file = \"../../tests/fixtures/audio/sine_440hz_3s.wav\"\n",
    "\n",
    "# Listen to the input\n",
    "print(\"Input audio:\")\n",
    "display(Audio(input_file))\n",
    "\n",
    "# Transcribe to MIDI\n",
    "print(\"\\nTranscribing...\")\n",
    "result = transcriber.transcribe(input_file)\n",
    "\n",
    "print(f\"\\nTranscription complete in {result.processing_time_seconds:.2f} seconds\")\n",
    "print(f\"Notes detected: {result.note_count}\")\n",
    "print(f\"Duration: {result.duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Note Events\n",
    "\n",
    "The transcription result contains a list of `NoteEvent` objects with detailed information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 10 notes\n",
    "print(\"First 10 notes:\\n\")\n",
    "for i, note in enumerate(result.notes[:10], 1):\n",
    "    print(f\"{i:2d}. {note.pitch_name:4s} | \"\n",
    "          f\"Time: {note.start_time:6.3f}s - {note.end_time:6.3f}s | \"\n",
    "          f\"Duration: {note.duration_ms:6.1f}ms | \"\n",
    "          f\"Velocity: {note.velocity:3d} | \"\n",
    "          f\"Freq: {note.frequency:6.1f}Hz | \"\n",
    "          f\"Confidence: {note.confidence:.2f}\")\n",
    "\n",
    "if result.note_count > 10:\n",
    "    print(f\"\\n... and {result.note_count - 10} more notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Note Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.note_count > 0:\n",
    "    # Get pitch range\n",
    "    min_pitch, max_pitch = result.pitch_range\n",
    "    min_note = result.notes[0]\n",
    "    max_note = result.notes[0]\n",
    "    \n",
    "    for note in result.notes:\n",
    "        if note.pitch == min_pitch:\n",
    "            min_note = note\n",
    "        if note.pitch == max_pitch:\n",
    "            max_note = note\n",
    "    \n",
    "    print(\"Transcription Statistics:\\n\")\n",
    "    print(f\"Total notes: {result.note_count}\")\n",
    "    print(f\"Duration: {result.duration:.2f}s\")\n",
    "    print(f\"Pitch range: {min_note.pitch_name} ({min_note.frequency:.1f} Hz) to \"\n",
    "          f\"{max_note.pitch_name} ({max_note.frequency:.1f} Hz)\")\n",
    "    print(f\"Average velocity: {result.average_velocity:.1f}\")\n",
    "    \n",
    "    # Calculate note density\n",
    "    if result.duration > 0:\n",
    "        note_density = result.note_count / result.duration\n",
    "        print(f\"Note density: {note_density:.1f} notes/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing the Piano Roll\n",
    "\n",
    "Let's create a piano roll visualization of the transcribed notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piano_roll(midi_result, max_notes=None, figsize=(14, 6)):\n",
    "    \"\"\"\n",
    "    Plot a piano roll visualization of MIDI notes.\n",
    "    \n",
    "    Args:\n",
    "        midi_result: MIDIResult object\n",
    "        max_notes: Maximum number of notes to display (None for all)\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    notes = midi_result.notes[:max_notes] if max_notes else midi_result.notes\n",
    "    \n",
    "    if not notes:\n",
    "        print(\"No notes to display\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot each note as a rectangle\n",
    "    for note in notes:\n",
    "        # Color by velocity\n",
    "        color = plt.cm.viridis(note.velocity / 127.0)\n",
    "        \n",
    "        # Draw note rectangle\n",
    "        rect = plt.Rectangle(\n",
    "            (note.start_time, note.pitch),\n",
    "            note.duration,\n",
    "            0.8,\n",
    "            facecolor=color,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            alpha=0.8\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # Set labels and limits\n",
    "    ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax.set_ylabel('MIDI Pitch', fontsize=12)\n",
    "    ax.set_title('Piano Roll Visualization', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Set y-axis to show all notes with some padding\n",
    "    min_pitch, max_pitch = midi_result.pitch_range\n",
    "    ax.set_ylim(min_pitch - 2, max_pitch + 2)\n",
    "    ax.set_xlim(0, midi_result.duration)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add colorbar for velocity\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, \n",
    "                                norm=plt.Normalize(vmin=0, vmax=127))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label('Velocity', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the transcription\n",
    "plot_piano_roll(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuring Transcription Parameters\n",
    "\n",
    "Fine-tune the transcription with custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration\n",
    "custom_config = TranscriptionConfig(\n",
    "    # Detection thresholds (0.1-0.9)\n",
    "    onset_thresh=0.5,      # Higher = fewer false positives, may miss quiet notes\n",
    "    frame_thresh=0.3,      # Higher = more confident note detection\n",
    "    \n",
    "    # Note filtering\n",
    "    minimum_note_length=58.0,  # Minimum note duration in milliseconds (10-200)\n",
    "    \n",
    "    # Frequency range (Hz)\n",
    "    minimum_frequency=32.7,    # C1 (20-500)\n",
    "    maximum_frequency=2093.0,  # C7 (1000-8000)\n",
    "    \n",
    "    # Advanced options\n",
    "    include_pitch_bends=False,  # Include pitch bend information\n",
    "    melodia_trick=True,         # Use melodia trick for better monophonic results\n",
    "    \n",
    "    # Processing\n",
    "    device=\"auto\",  # \"auto\", \"cuda\", or \"cpu\"\n",
    ")\n",
    "\n",
    "print(\"Custom Transcription Configuration:\\n\")\n",
    "print(f\"  Onset threshold: {custom_config.onset_thresh}\")\n",
    "print(f\"  Frame threshold: {custom_config.frame_thresh}\")\n",
    "print(f\"  Min note length: {custom_config.minimum_note_length}ms\")\n",
    "print(f\"  Frequency range: {custom_config.minimum_frequency:.1f} - {custom_config.maximum_frequency:.1f} Hz\")\n",
    "print(f\"  Melodia trick: {custom_config.melodia_trick}\")\n",
    "print(f\"  Device: {custom_config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different Configurations\n",
    "\n",
    "Let's compare conservative vs. sensitive detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservative: Fewer false positives, may miss quiet notes\n",
    "conservative_config = TranscriptionConfig(\n",
    "    onset_thresh=0.7,\n",
    "    frame_thresh=0.5,\n",
    "    minimum_note_length=100.0,\n",
    ")\n",
    "\n",
    "# Sensitive: More notes detected, may have false positives\n",
    "sensitive_config = TranscriptionConfig(\n",
    "    onset_thresh=0.3,\n",
    "    frame_thresh=0.2,\n",
    "    minimum_note_length=30.0,\n",
    ")\n",
    "\n",
    "print(\"Configuration Comparison:\\n\")\n",
    "print(\"Conservative (fewer false positives):\")\n",
    "print(f\"  Onset: {conservative_config.onset_thresh}, Frame: {conservative_config.frame_thresh}\")\n",
    "print(f\"  Min length: {conservative_config.minimum_note_length}ms\\n\")\n",
    "\n",
    "print(\"Sensitive (more notes detected):\")\n",
    "print(f\"  Onset: {sensitive_config.onset_thresh}, Frame: {sensitive_config.frame_thresh}\")\n",
    "print(f\"  Min length: {sensitive_config.minimum_note_length}ms\")\n",
    "\n",
    "# Uncomment to test different configurations:\n",
    "# transcriber_conservative = MIDITranscriber(config=conservative_config)\n",
    "# result_conservative = transcriber_conservative.transcribe(input_file)\n",
    "# print(f\"\\nConservative notes: {result_conservative.note_count}\")\n",
    "\n",
    "# transcriber_sensitive = MIDITranscriber(config=sensitive_config)\n",
    "# result_sensitive = transcriber_sensitive.transcribe(input_file)\n",
    "# print(f\"Sensitive notes: {result_sensitive.note_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving MIDI Files\n",
    "\n",
    "Export transcription results to standard MIDI format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"./output/midi\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save MIDI file\n",
    "midi_path = output_dir / \"transcription.mid\"\n",
    "\n",
    "# The transcribe method can save directly\n",
    "result_with_save = transcriber.transcribe(\n",
    "    input_file,\n",
    "    output_midi_path=str(midi_path)\n",
    ")\n",
    "\n",
    "print(f\"MIDI file saved to: {midi_path}\")\n",
    "print(f\"File size: {midi_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# You can also save an existing result\n",
    "# save_midi(midi_path, result.notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MIDI Files\n",
    "\n",
    "Load and inspect saved MIDI files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MIDI file back\n",
    "if midi_path.exists():\n",
    "    loaded_notes = load_midi(midi_path)\n",
    "    \n",
    "    print(f\"Loaded {len(loaded_notes)} notes from MIDI file\\n\")\n",
    "    \n",
    "    # Display first few notes\n",
    "    print(\"First 5 notes:\")\n",
    "    for i, note in enumerate(loaded_notes[:5], 1):\n",
    "        print(f\"{i}. {note.pitch_name} at {note.start_time:.3f}s, \"\n",
    "              f\"duration: {note.duration_ms:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with Time Ranges\n",
    "\n",
    "Extract notes from specific time ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.note_count > 0:\n",
    "    # Get notes from first 2 seconds\n",
    "    first_section = result.get_notes_in_range(0.0, 2.0)\n",
    "    print(f\"Notes in first 2 seconds: {len(first_section)}\")\n",
    "    \n",
    "    # Get notes from middle section\n",
    "    mid_point = result.duration / 2\n",
    "    middle_section = result.get_notes_in_range(mid_point - 1.0, mid_point + 1.0)\n",
    "    print(f\"Notes in middle 2 seconds: {len(middle_section)}\")\n",
    "    \n",
    "    # Get notes from last second\n",
    "    last_section = result.get_notes_in_range(result.duration - 1.0, result.duration)\n",
    "    print(f\"Notes in last second: {len(last_section)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Analysis\n",
    "\n",
    "Perform more detailed analysis of the transcription:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_transcription(midi_result):\n",
    "    \"\"\"\n",
    "    Perform detailed analysis of transcription result.\n",
    "    \"\"\"\n",
    "    if midi_result.note_count == 0:\n",
    "        print(\"No notes to analyze\")\n",
    "        return\n",
    "    \n",
    "    notes = midi_result.notes\n",
    "    \n",
    "    # Calculate statistics\n",
    "    durations = [note.duration for note in notes]\n",
    "    velocities = [note.velocity for note in notes]\n",
    "    pitches = [note.pitch for note in notes]\n",
    "    \n",
    "    print(\"Detailed Transcription Analysis\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Duration statistics\n",
    "    print(\"\\nNote Durations:\")\n",
    "    print(f\"  Average: {np.mean(durations):.3f}s ({np.mean(durations)*1000:.1f}ms)\")\n",
    "    print(f\"  Median: {np.median(durations):.3f}s\")\n",
    "    print(f\"  Min: {np.min(durations):.3f}s, Max: {np.max(durations):.3f}s\")\n",
    "    print(f\"  Std dev: {np.std(durations):.3f}s\")\n",
    "    \n",
    "    # Velocity statistics\n",
    "    print(\"\\nVelocities:\")\n",
    "    print(f\"  Average: {np.mean(velocities):.1f}\")\n",
    "    print(f\"  Range: {np.min(velocities)} - {np.max(velocities)}\")\n",
    "    print(f\"  Std dev: {np.std(velocities):.1f}\")\n",
    "    \n",
    "    # Pitch statistics\n",
    "    print(\"\\nPitch Distribution:\")\n",
    "    unique_pitches = len(set(pitches))\n",
    "    print(f\"  Unique pitches: {unique_pitches}\")\n",
    "    print(f\"  Most common pitch: {max(set(pitches), key=pitches.count)} \"\n",
    "          f\"({notes[pitches.index(max(set(pitches), key=pitches.count))].pitch_name})\")\n",
    "    \n",
    "    # Calculate intervals between notes\n",
    "    if len(notes) > 1:\n",
    "        intervals = [notes[i+1].start_time - notes[i].end_time \n",
    "                    for i in range(len(notes)-1)]\n",
    "        positive_intervals = [i for i in intervals if i > 0]\n",
    "        \n",
    "        print(\"\\nNote Gaps:\")\n",
    "        if positive_intervals:\n",
    "            print(f\"  Average gap: {np.mean(positive_intervals):.3f}s\")\n",
    "            print(f\"  Notes with gaps: {len(positive_intervals)} \"\n",
    "                  f\"({100*len(positive_intervals)/len(intervals):.1f}%)\")\n",
    "        else:\n",
    "            print(\"  No gaps between notes (legato)\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    confidences = [note.confidence for note in notes]\n",
    "    print(\"\\nConfidence Scores:\")\n",
    "    print(f\"  Average: {np.mean(confidences):.3f}\")\n",
    "    print(f\"  Min: {np.min(confidences):.3f}, Max: {np.max(confidences):.3f}\")\n",
    "    print(f\"  High confidence (>0.8): {sum(1 for c in confidences if c > 0.8)} notes\")\n",
    "    print(f\"  Low confidence (<0.5): {sum(1 for c in confidences if c < 0.5)} notes\")\n",
    "\n",
    "# Analyze the transcription\n",
    "analyze_transcription(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Transcription\n",
    "\n",
    "Transcribe multiple audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_transcribe(input_dir, output_dir, config=None):\n",
    "    \"\"\"\n",
    "    Transcribe all audio files in a directory to MIDI.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing audio files\n",
    "        output_dir: Directory for MIDI outputs\n",
    "        config: Optional TranscriptionConfig\n",
    "    \"\"\"\n",
    "    transcriber = MIDITranscriber(config=config)\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Find all audio files\n",
    "    audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']\n",
    "    audio_files = []\n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(input_path.glob(f'*{ext}'))\n",
    "    \n",
    "    print(f\"Found {len(audio_files)} audio files\\n\")\n",
    "    \n",
    "    results = []\n",
    "    for i, audio_file in enumerate(audio_files, 1):\n",
    "        print(f\"[{i}/{len(audio_files)}] Transcribing: {audio_file.name}\")\n",
    "        \n",
    "        midi_file = output_path / f\"{audio_file.stem}.mid\"\n",
    "        \n",
    "        try:\n",
    "            result = transcriber.transcribe(\n",
    "                str(audio_file),\n",
    "                output_midi_path=str(midi_file)\n",
    "            )\n",
    "            results.append((audio_file.name, result))\n",
    "            print(f\"  ✓ {result.note_count} notes in {result.processing_time_seconds:.1f}s\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\\n\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nBatch Transcription Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    total_notes = sum(result.note_count for _, result in results)\n",
    "    total_time = sum(result.processing_time_seconds for _, result in results)\n",
    "    print(f\"Files processed: {len(results)}\")\n",
    "    print(f\"Total notes: {total_notes}\")\n",
    "    print(f\"Total processing time: {total_time:.1f}s\")\n",
    "    print(f\"Average notes per file: {total_notes/len(results):.1f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# results = batch_transcribe(\n",
    "#     input_dir=\"./audio_files\",\n",
    "#     output_dir=\"./output/midi_batch\",\n",
    "#     config=TranscriptionConfig(onset_thresh=0.5)\n",
    "# )\n",
    "\n",
    "print(\"Batch transcription function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "### 1. Audio Preparation\n",
    "\n",
    "- **Best results**: Monophonic melodies (single note at a time)\n",
    "- **Good results**: Polyphonic music with clear melody\n",
    "- **Challenging**: Dense polyphonic music, percussion\n",
    "- Clean, high-quality audio produces better transcriptions\n",
    "- Consider extracting vocals stem first for vocal melodies\n",
    "\n",
    "### 2. Parameter Tuning\n",
    "\n",
    "**Onset Threshold (`onset_thresh`):**\n",
    "- Lower (0.3): More notes, may include false positives\n",
    "- Higher (0.7): Fewer notes, only confident detections\n",
    "- Default (0.5): Good balance for most cases\n",
    "\n",
    "**Frame Threshold (`frame_thresh`):**\n",
    "- Controls note sustain detection\n",
    "- Lower values capture longer notes better\n",
    "- Higher values for staccato passages\n",
    "\n",
    "**Minimum Note Length:**\n",
    "- Increase to filter out very short notes\n",
    "- Decrease for fast passages\n",
    "- Default (58ms) works well for most music\n",
    "\n",
    "### 3. Use Cases\n",
    "\n",
    "- **Vocal melodies**: Extract vocals stem, use default settings\n",
    "- **Piano**: Use sensitive settings, may need manual cleanup\n",
    "- **Guitar**: Works best with clean tones\n",
    "- **Synth leads**: Usually excellent results\n",
    "- **Bass lines**: Consider limiting frequency range\n",
    "\n",
    "### 4. Performance Optimization\n",
    "\n",
    "- Enable GPU with `device=\"cuda\"` for faster processing\n",
    "- Process shorter segments for long files\n",
    "- Use batch processing for multiple files\n",
    "\n",
    "### 5. Common Issues\n",
    "\n",
    "- **Too many notes**: Increase thresholds or minimum note length\n",
    "- **Missing notes**: Lower thresholds, check frequency range\n",
    "- **Wrong octave**: Check input audio sample rate\n",
    "- **Choppy notes**: Lower `onset_thresh` and `frame_thresh`\n",
    "\n",
    "### 6. Post-Processing\n",
    "\n",
    "- Use a MIDI editor for final cleanup\n",
    "- Quantize notes to musical grid if needed\n",
    "- Adjust velocities for more musical expression\n",
    "- Consider splitting into multiple tracks by pitch range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "✓ Transcribe audio to MIDI notes  \n",
    "✓ Work with note events and their properties  \n",
    "✓ Visualize piano rolls  \n",
    "✓ Configure transcription parameters  \n",
    "✓ Compare different detection sensitivities  \n",
    "✓ Save and load MIDI files  \n",
    "✓ Extract notes from time ranges  \n",
    "✓ Perform detailed transcription analysis  \n",
    "✓ Batch process multiple files  \n",
    "✓ Apply best practices for transcription  \n",
    "\n",
    "**Next Steps:**\n",
    "- Combine with stem separation for better results\n",
    "- Learn audio analysis in notebook 03\n",
    "- Apply effects processing in notebook 04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
