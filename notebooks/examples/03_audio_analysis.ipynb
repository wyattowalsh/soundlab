{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Analysis with SoundLab\n",
    "\n",
    "This notebook demonstrates SoundLab's comprehensive audio analysis capabilities.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Detect tempo and BPM\n",
    "- Identify musical key\n",
    "- Measure loudness (LUFS)\n",
    "- Extract spectral features\n",
    "- Detect onsets and transients\n",
    "- Comprehensive audio analysis\n",
    "- Best practices for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundlab\n",
    "from soundlab.analysis import (\n",
    "    analyze_audio,\n",
    "    detect_tempo,\n",
    "    detect_key,\n",
    "    measure_loudness,\n",
    ")\n",
    "from soundlab.io import load_audio\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization and audio playback\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"SoundLab version: {soundlab.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comprehensive Audio Analysis\n",
    "\n",
    "The simplest way to analyze audio is to use the `analyze_audio()` function, which performs all analyses at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your audio file\n",
    "input_file = \"../../tests/fixtures/audio/music_like_5s.wav\"\n",
    "\n",
    "# Listen to the input\n",
    "print(\"Input audio:\")\n",
    "display(Audio(input_file))\n",
    "\n",
    "# Perform comprehensive analysis\n",
    "print(\"\\nAnalyzing audio...\")\n",
    "analysis = analyze_audio(input_file)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in analysis.summary.items():\n",
    "    print(f\"  {key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Analysis Results\n",
    "\n",
    "Let's examine each component of the analysis in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detailed Analysis Results\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic audio properties\n",
    "print(\"\\nüìä Audio Properties:\")\n",
    "print(f\"  Duration: {analysis.duration_seconds:.2f} seconds\")\n",
    "print(f\"  Sample rate: {analysis.sample_rate} Hz\")\n",
    "print(f\"  Channels: {analysis.channels}\")\n",
    "\n",
    "# Tempo analysis\n",
    "if analysis.tempo:\n",
    "    print(\"\\nüéµ Tempo:\")\n",
    "    print(f\"  BPM: {analysis.tempo.bpm:.1f}\")\n",
    "    print(f\"  Confidence: {analysis.tempo.confidence:.2%}\")\n",
    "    print(f\"  Beat interval: {analysis.tempo.beat_interval:.3f}s\")\n",
    "    print(f\"  Detected beats: {analysis.tempo.beat_count}\")\n",
    "\n",
    "# Key detection\n",
    "if analysis.key:\n",
    "    print(\"\\nüéπ Key:\")\n",
    "    print(f\"  Key: {analysis.key.name}\")\n",
    "    print(f\"  Confidence: {analysis.key.confidence:.2%}\")\n",
    "    print(f\"  Camelot: {analysis.key.camelot}\")\n",
    "    print(f\"  Open Key: {analysis.key.open_key}\")\n",
    "\n",
    "# Loudness analysis\n",
    "if analysis.loudness:\n",
    "    print(\"\\nüîä Loudness:\")\n",
    "    print(f\"  Integrated LUFS: {analysis.loudness.integrated_lufs:.1f}\")\n",
    "    if analysis.loudness.loudness_range:\n",
    "        print(f\"  Loudness range: {analysis.loudness.loudness_range:.1f} LU\")\n",
    "    if analysis.loudness.true_peak_db:\n",
    "        print(f\"  True peak: {analysis.loudness.true_peak_db:.1f} dBTP\")\n",
    "    print(f\"  Broadcast safe: {'‚úì Yes' if analysis.loudness.is_broadcast_safe else '‚úó No'}\")\n",
    "    print(f\"  Streaming optimized: {'‚úì Yes' if analysis.loudness.is_streaming_optimized else '‚úó No'}\")\n",
    "\n",
    "# Spectral analysis\n",
    "if analysis.spectral:\n",
    "    print(\"\\nüåà Spectral:\")\n",
    "    print(f\"  Centroid: {analysis.spectral.spectral_centroid:.1f} Hz\")\n",
    "    print(f\"  Bandwidth: {analysis.spectral.spectral_bandwidth:.1f} Hz\")\n",
    "    print(f\"  Rolloff: {analysis.spectral.spectral_rolloff:.1f} Hz\")\n",
    "    print(f\"  Flatness: {analysis.spectral.spectral_flatness:.3f}\")\n",
    "    print(f\"  Brightness: {analysis.spectral.brightness}\")\n",
    "    print(f\"  Zero crossing rate: {analysis.spectral.zero_crossing_rate:.4f}\")\n",
    "\n",
    "# Onset detection\n",
    "if analysis.onsets:\n",
    "    print(\"\\n‚ö° Onsets:\")\n",
    "    print(f\"  Onset count: {analysis.onsets.onset_count}\")\n",
    "    print(f\"  Average interval: {analysis.onsets.average_interval:.3f}s\")\n",
    "    if analysis.onsets.onset_count > 0:\n",
    "        print(f\"  First onset: {analysis.onsets.onset_times[0]:.3f}s\")\n",
    "        print(f\"  Last onset: {analysis.onsets.onset_times[-1]:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tempo Detection (BPM)\n",
    "\n",
    "Detect the tempo and beats in audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect tempo\n",
    "tempo_result = detect_tempo(input_file)\n",
    "\n",
    "print(\"Tempo Detection Results:\\n\")\n",
    "print(f\"BPM: {tempo_result.bpm:.2f}\")\n",
    "print(f\"Confidence: {tempo_result.confidence:.1%}\")\n",
    "print(f\"Beat interval: {tempo_result.beat_interval:.3f} seconds\")\n",
    "print(f\"Detected beats: {tempo_result.beat_count}\")\n",
    "\n",
    "# Display beat timestamps\n",
    "if tempo_result.beats:\n",
    "    print(f\"\\nFirst 10 beats (seconds):\")\n",
    "    for i, beat_time in enumerate(tempo_result.beats[:10], 1):\n",
    "        print(f\"  Beat {i:2d}: {beat_time:.3f}s\")\n",
    "    \n",
    "    if tempo_result.beat_count > 10:\n",
    "        print(f\"  ... and {tempo_result.beat_count - 10} more beats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Beat Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beats(audio_file, tempo_result, figsize=(14, 4)):\n",
    "    \"\"\"\n",
    "    Visualize detected beats on waveform.\n",
    "    \"\"\"\n",
    "    # Load audio\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    \n",
    "    # Create time axis\n",
    "    time = np.arange(len(audio)) / sr\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot waveform\n",
    "    ax.plot(time, audio, alpha=0.6, linewidth=0.5, color='steelblue')\n",
    "    \n",
    "    # Plot beats\n",
    "    for beat_time in tempo_result.beats:\n",
    "        ax.axvline(x=beat_time, color='red', alpha=0.7, \n",
    "                  linewidth=1.5, linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax.set_ylabel('Amplitude', fontsize=12)\n",
    "    ax.set_title(f'Beat Detection (BPM: {tempo_result.bpm:.1f})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize beats\n",
    "if tempo_result.beat_count > 0:\n",
    "    plot_beats(input_file, tempo_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Key Detection\n",
    "\n",
    "Detect the musical key of audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect key\n",
    "key_result = detect_key(input_file)\n",
    "\n",
    "print(\"Key Detection Results:\\n\")\n",
    "print(f\"Key: {key_result.name}\")\n",
    "print(f\"Confidence: {key_result.confidence:.1%}\")\n",
    "print(f\"Camelot notation: {key_result.camelot}\")\n",
    "print(f\"Open Key notation: {key_result.open_key}\")\n",
    "\n",
    "# Show all key correlations\n",
    "if key_result.all_correlations:\n",
    "    print(\"\\nAll Key Correlations (top 5):\")\n",
    "    sorted_keys = sorted(key_result.all_correlations.items(), \n",
    "                        key=lambda x: x[1], reverse=True)\n",
    "    for key_name, correlation in sorted_keys[:5]:\n",
    "        bar = '‚ñà' * int(correlation * 20)\n",
    "        print(f\"  {key_name:12s} {correlation:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Key Notations\n",
    "\n",
    "SoundLab provides multiple key notation systems for DJs and musicians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Key Notation Systems:\\n\")\n",
    "print(f\"Standard: {key_result.key.value} {key_result.mode.value}\")\n",
    "print(f\"Camelot: {key_result.camelot} (for harmonic mixing)\")\n",
    "print(f\"Open Key: {key_result.open_key} (alternative DJ notation)\")\n",
    "\n",
    "print(\"\\nCompatible Keys for Mixing:\")\n",
    "# Extract camelot number and letter\n",
    "camelot_num = int(''.join(filter(str.isdigit, key_result.camelot)))\n",
    "camelot_letter = key_result.camelot[-1]\n",
    "\n",
    "# Compatible keys in Camelot system\n",
    "compatible = [\n",
    "    f\"{camelot_num}{camelot_letter} (same key)\",\n",
    "    f\"{camelot_num}{'B' if camelot_letter == 'A' else 'A'} (relative major/minor)\",\n",
    "    f\"{camelot_num + 1 if camelot_num < 12 else 1}{camelot_letter} (+1)\",\n",
    "    f\"{camelot_num - 1 if camelot_num > 1 else 12}{camelot_letter} (-1)\",\n",
    "]\n",
    "\n",
    "for comp in compatible:\n",
    "    print(f\"  ‚Ä¢ {comp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loudness Analysis (LUFS)\n",
    "\n",
    "Measure loudness using broadcast standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure loudness\n",
    "loudness_result = measure_loudness(input_file)\n",
    "\n",
    "print(\"Loudness Analysis Results:\\n\")\n",
    "print(f\"Integrated LUFS: {loudness_result.integrated_lufs:.2f}\")\n",
    "\n",
    "if loudness_result.loudness_range:\n",
    "    print(f\"Loudness Range: {loudness_result.loudness_range:.2f} LU\")\n",
    "    \n",
    "if loudness_result.true_peak_db:\n",
    "    print(f\"True Peak: {loudness_result.true_peak_db:.2f} dBTP\")\n",
    "    \n",
    "if loudness_result.dynamic_range_db:\n",
    "    print(f\"Dynamic Range: {loudness_result.dynamic_range_db:.2f} dB\")\n",
    "\n",
    "# Standards compliance\n",
    "print(\"\\nStandards Compliance:\")\n",
    "print(f\"  Broadcast safe (-24 to -14 LUFS): \"\n",
    "      f\"{'‚úì Yes' if loudness_result.is_broadcast_safe else '‚úó No'}\")\n",
    "print(f\"  Streaming optimized (-14 LUFS): \"\n",
    "      f\"{'‚úì Yes' if loudness_result.is_streaming_optimized else '‚úó No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding LUFS Values\n",
    "\n",
    "Here's a guide to typical LUFS values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_lufs(lufs_value):\n",
    "    \"\"\"\n",
    "    Interpret LUFS value and provide recommendations.\n",
    "    \"\"\"\n",
    "    print(f\"Current LUFS: {lufs_value:.1f}\\n\")\n",
    "    \n",
    "    # Reference values\n",
    "    references = [\n",
    "        (-6, \"Very loud, highly compressed (modern pop/EDM)\"),\n",
    "        (-9, \"Loud, compressed (rock, electronic)\"),\n",
    "        (-11, \"Moderately loud (hip-hop, R&B)\"),\n",
    "        (-14, \"Streaming optimal (Spotify, Apple Music target)\"),\n",
    "        (-16, \"Broadcast standard (TV, radio)\"),\n",
    "        (-20, \"Quiet/dynamic (acoustic, classical)\"),\n",
    "        (-23, \"Very quiet (dialogue, ambient)\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"Reference Levels:\")\n",
    "    for ref_lufs, description in references:\n",
    "        marker = \"‚Üê YOU ARE HERE\" if abs(lufs_value - ref_lufs) < 2 else \"\"\n",
    "        print(f\"  {ref_lufs:3d} LUFS: {description} {marker}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\nRecommendations:\")\n",
    "    if lufs_value > -10:\n",
    "        print(\"  ‚ö† Very loud - may sound distorted or fatiguing\")\n",
    "        print(\"  ‚Üí Consider reducing gain or limiting\")\n",
    "    elif -14 <= lufs_value <= -10:\n",
    "        print(\"  ‚úì Good for streaming platforms\")\n",
    "        print(\"  ‚Üí Optimal for Spotify, Apple Music, YouTube\")\n",
    "    elif -20 <= lufs_value < -14:\n",
    "        print(\"  ‚úì Good dynamic range\")\n",
    "        print(\"  ‚Üí May be normalized (increased) by streaming services\")\n",
    "    else:\n",
    "        print(\"  ‚ö† Very quiet\")\n",
    "        print(\"  ‚Üí Consider increasing gain to improve audibility\")\n",
    "\n",
    "interpret_lufs(loudness_result.integrated_lufs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spectral Analysis\n",
    "\n",
    "Extract spectral features to understand frequency content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spectral analysis from comprehensive analysis\n",
    "if analysis.spectral:\n",
    "    spectral = analysis.spectral\n",
    "    \n",
    "    print(\"Spectral Analysis Results:\\n\")\n",
    "    print(f\"Spectral Centroid: {spectral.spectral_centroid:.1f} Hz\")\n",
    "    print(f\"  (average frequency, weighted by amplitude)\")\n",
    "    print(f\"\\nSpectral Bandwidth: {spectral.spectral_bandwidth:.1f} Hz\")\n",
    "    print(f\"  (spread of frequencies around centroid)\")\n",
    "    print(f\"\\nSpectral Rolloff: {spectral.spectral_rolloff:.1f} Hz\")\n",
    "    print(f\"  (frequency below which 95% of energy is concentrated)\")\n",
    "    print(f\"\\nSpectral Flatness: {spectral.spectral_flatness:.3f}\")\n",
    "    print(f\"  (0 = tonal, 1 = noise-like)\")\n",
    "    print(f\"\\nZero Crossing Rate: {spectral.zero_crossing_rate:.4f}\")\n",
    "    print(f\"  (rate of sign changes, correlates with noisiness)\")\n",
    "    print(f\"\\nBrightness: {spectral.brightness}\")\n",
    "    print(f\"  (qualitative assessment based on centroid)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(audio_file, figsize=(14, 8)):\n",
    "    \"\"\"\n",
    "    Plot spectrum and spectral features.\n",
    "    \"\"\"\n",
    "    import librosa\n",
    "    import librosa.display\n",
    "    \n",
    "    # Load audio\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    \n",
    "    # Compute spectrogram\n",
    "    D = librosa.stft(audio)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    \n",
    "    # Compute spectral features over time\n",
    "    centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize)\n",
    "    \n",
    "    # Plot spectrogram\n",
    "    img = librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz', \n",
    "                                   ax=ax1, cmap='viridis')\n",
    "    ax1.set_ylabel('Frequency (Hz)', fontsize=10)\n",
    "    ax1.set_title('Spectrogram with Spectral Features', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Plot spectral centroid and rolloff\n",
    "    times = librosa.times_like(centroid, sr=sr)\n",
    "    ax1.plot(times, centroid, label='Centroid', color='red', linewidth=2)\n",
    "    ax1.plot(times, rolloff, label='Rolloff', color='yellow', linewidth=2)\n",
    "    ax1.legend(loc='upper right')\n",
    "    \n",
    "    fig.colorbar(img, ax=ax1, format='%+2.0f dB')\n",
    "    \n",
    "    # Plot waveform\n",
    "    time = np.arange(len(audio)) / sr\n",
    "    ax2.plot(time, audio, linewidth=0.5, alpha=0.7, color='steelblue')\n",
    "    ax2.set_xlabel('Time (seconds)', fontsize=10)\n",
    "    ax2.set_ylabel('Amplitude', fontsize=10)\n",
    "    ax2.set_title('Waveform', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize spectrum\n",
    "plot_spectrum(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Onset Detection\n",
    "\n",
    "Detect transients and note onsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get onset analysis from comprehensive analysis\n",
    "if analysis.onsets:\n",
    "    onsets = analysis.onsets\n",
    "    \n",
    "    print(\"Onset Detection Results:\\n\")\n",
    "    print(f\"Total onsets detected: {onsets.onset_count}\")\n",
    "    print(f\"Average interval: {onsets.average_interval:.3f} seconds\")\n",
    "    \n",
    "    if onsets.onset_count > 0:\n",
    "        # Calculate onset density\n",
    "        duration = analysis.duration_seconds\n",
    "        density = onsets.onset_count / duration\n",
    "        print(f\"Onset density: {density:.1f} onsets/second\")\n",
    "        \n",
    "        # Display first 10 onsets\n",
    "        print(f\"\\nFirst 10 onsets (with strength):\")\n",
    "        for i in range(min(10, onsets.onset_count)):\n",
    "            time = onsets.onset_times[i]\n",
    "            strength = onsets.onset_strengths[i]\n",
    "            bar = '‚ñà' * int(strength * 20)\n",
    "            print(f\"  {i+1:2d}. {time:6.3f}s  {strength:.3f} {bar}\")\n",
    "        \n",
    "        if onsets.onset_count > 10:\n",
    "            print(f\"  ... and {onsets.onset_count - 10} more onsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_onsets(audio_file, onset_result, figsize=(14, 6)):\n",
    "    \"\"\"\n",
    "    Visualize detected onsets on waveform.\n",
    "    \"\"\"\n",
    "    # Load audio\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    time = np.arange(len(audio)) / sr\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, \n",
    "                                    gridspec_kw={'height_ratios': [2, 1]})\n",
    "    \n",
    "    # Plot waveform with onset markers\n",
    "    ax1.plot(time, audio, alpha=0.6, linewidth=0.5, color='steelblue')\n",
    "    \n",
    "    # Mark onsets\n",
    "    for onset_time in onset_result.onset_times:\n",
    "        ax1.axvline(x=onset_time, color='red', alpha=0.7, \n",
    "                   linewidth=1.5, linestyle='--')\n",
    "    \n",
    "    ax1.set_ylabel('Amplitude', fontsize=10)\n",
    "    ax1.set_title(f'Onset Detection ({onset_result.onset_count} onsets)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot onset strength function\n",
    "    if onset_result.onset_strengths:\n",
    "        ax2.plot(onset_result.onset_times, onset_result.onset_strengths, \n",
    "                'o-', color='red', markersize=4)\n",
    "        ax2.set_ylabel('Onset Strength', fontsize=10)\n",
    "        ax2.set_xlabel('Time (seconds)', fontsize=10)\n",
    "        ax2.set_title('Onset Strength Function', fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize onsets\n",
    "if analysis.onsets and analysis.onsets.onset_count > 0:\n",
    "    plot_onsets(input_file, analysis.onsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Analysis\n",
    "\n",
    "Analyze multiple audio files and compare results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_analyze(input_dir, output_csv=None):\n",
    "    \"\"\"\n",
    "    Analyze all audio files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing audio files\n",
    "        output_csv: Optional path to save results as CSV\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    \n",
    "    # Find all audio files\n",
    "    audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']\n",
    "    audio_files = []\n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(input_path.glob(f'*{ext}'))\n",
    "    \n",
    "    print(f\"Found {len(audio_files)} audio files\\n\")\n",
    "    \n",
    "    results = []\n",
    "    for i, audio_file in enumerate(audio_files, 1):\n",
    "        print(f\"[{i}/{len(audio_files)}] Analyzing: {audio_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            analysis = analyze_audio(str(audio_file))\n",
    "            \n",
    "            # Extract key metrics\n",
    "            result = {\n",
    "                'filename': audio_file.name,\n",
    "                'duration': analysis.duration_seconds,\n",
    "                'sample_rate': analysis.sample_rate,\n",
    "                'channels': analysis.channels,\n",
    "            }\n",
    "            \n",
    "            if analysis.tempo:\n",
    "                result['bpm'] = analysis.tempo.bpm\n",
    "                result['tempo_confidence'] = analysis.tempo.confidence\n",
    "            \n",
    "            if analysis.key:\n",
    "                result['key'] = analysis.key.name\n",
    "                result['camelot'] = analysis.key.camelot\n",
    "                result['key_confidence'] = analysis.key.confidence\n",
    "            \n",
    "            if analysis.loudness:\n",
    "                result['lufs'] = analysis.loudness.integrated_lufs\n",
    "                result['loudness_range'] = analysis.loudness.loudness_range\n",
    "            \n",
    "            if analysis.spectral:\n",
    "                result['brightness'] = analysis.spectral.brightness\n",
    "                result['spectral_centroid'] = analysis.spectral.spectral_centroid\n",
    "            \n",
    "            if analysis.onsets:\n",
    "                result['onset_count'] = analysis.onsets.onset_count\n",
    "            \n",
    "            results.append(result)\n",
    "            print(f\"  ‚úì Complete\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error: {e}\\n\")\n",
    "            continue\n",
    "    \n",
    "    # Display summary table\n",
    "    if results:\n",
    "        print(\"\\nAnalysis Summary:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Print header\n",
    "        print(f\"{'File':<30} {'BPM':<8} {'Key':<12} {'LUFS':<8} {'Brightness':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Print results\n",
    "        for result in results:\n",
    "            filename = result['filename'][:28]\n",
    "            bpm = f\"{result.get('bpm', 0):.1f}\" if 'bpm' in result else 'N/A'\n",
    "            key = result.get('key', 'N/A')\n",
    "            lufs = f\"{result.get('lufs', 0):.1f}\" if 'lufs' in result else 'N/A'\n",
    "            brightness = result.get('brightness', 'N/A')\n",
    "            \n",
    "            print(f\"{filename:<30} {bpm:<8} {key:<12} {lufs:<8} {brightness:<12}\")\n",
    "    \n",
    "    # Save to CSV if requested\n",
    "    if output_csv and results:\n",
    "        import csv\n",
    "        \n",
    "        with open(output_csv, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "        \n",
    "        print(f\"\\nResults saved to: {output_csv}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# results = batch_analyze(\n",
    "#     input_dir=\"../../tests/fixtures/audio\",\n",
    "#     output_csv=\"./output/analysis_results.csv\"\n",
    "# )\n",
    "\n",
    "print(\"Batch analysis function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "### 1. Tempo Detection\n",
    "\n",
    "- **Works best**: Clear, steady rhythms with prominent drums\n",
    "- **Challenging**: Rubato, tempo changes, ambient music\n",
    "- **Tip**: For electronic music, results are usually very accurate\n",
    "- **Double tempo**: If BPM seems 2x too high/low, it's detecting on/off-beat\n",
    "\n",
    "### 2. Key Detection\n",
    "\n",
    "- **Works best**: Tonal music with clear harmonic content\n",
    "- **Challenging**: Atonal music, chromatic passages, modal music\n",
    "- **Tip**: Check confidence score - above 0.7 is usually reliable\n",
    "- **Major/Minor**: Algorithm may confuse relative major/minor keys\n",
    "\n",
    "### 3. Loudness (LUFS)\n",
    "\n",
    "**Target LUFS by platform:**\n",
    "- Spotify: -14 LUFS\n",
    "- Apple Music: -16 LUFS\n",
    "- YouTube: -13 LUFS\n",
    "- Broadcast TV: -23 LUFS (EBU R128)\n",
    "- Broadcast Radio: -16 LUFS\n",
    "\n",
    "**Tips:**\n",
    "- True peak should be below -1.0 dBTP to avoid clipping\n",
    "- Higher loudness range (LU) = more dynamic\n",
    "- Streaming services normalize audio to their target\n",
    "\n",
    "### 4. Spectral Analysis\n",
    "\n",
    "**Spectral Centroid:**\n",
    "- < 1500 Hz: Dark, bass-heavy\n",
    "- 1500-3000 Hz: Balanced\n",
    "- > 3000 Hz: Bright, treble-heavy\n",
    "\n",
    "**Spectral Flatness:**\n",
    "- Close to 0: Tonal (pitched instruments)\n",
    "- Close to 1: Noise-like (percussion, white noise)\n",
    "\n",
    "**Zero Crossing Rate:**\n",
    "- Higher values = more high-frequency content\n",
    "- Useful for speech/music discrimination\n",
    "\n",
    "### 5. Onset Detection\n",
    "\n",
    "- **Use cases**: Rhythmic analysis, beat tracking, audio segmentation\n",
    "- **High onset density**: Complex, busy music\n",
    "- **Low onset density**: Sustained, ambient music\n",
    "- **Tip**: Useful for automatic slicing and sample extraction\n",
    "\n",
    "### 6. Performance Optimization\n",
    "\n",
    "- Use `analyze_audio()` for all-in-one analysis (more efficient)\n",
    "- For specific features, call individual functions\n",
    "- Enable GPU acceleration where available\n",
    "- Process shorter segments for very long files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "‚úì Perform comprehensive audio analysis  \n",
    "‚úì Detect tempo and visualize beats  \n",
    "‚úì Identify musical keys with DJ notations  \n",
    "‚úì Measure loudness for different platforms  \n",
    "‚úì Extract and interpret spectral features  \n",
    "‚úì Detect onsets and transients  \n",
    "‚úì Batch analyze multiple files  \n",
    "‚úì Apply best practices for each analysis type  \n",
    "\n",
    "**Next Steps:**\n",
    "- Combine analysis with stem separation\n",
    "- Use tempo detection for beat-synced effects\n",
    "- Apply effects processing in notebook 04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
